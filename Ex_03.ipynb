{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77c35791",
   "metadata": {},
   "source": [
    "# Project \n",
    "\n",
    "## The Challenge\n",
    "The Swedish Forest Agency has mapped high conservation value forests, though field surveys. Approximately 67 000 areas (=nyckelbiotoper in Swedish) are delimited in the database.\n",
    "However, it is costly and time consuming to conduct field surveys. So it is proposed to consider national continuous cover datasets, such as the laser scanning, satellite images and aerial photos, to identify high conservation value forests.\n",
    "\n",
    "### The Problem:\n",
    "To know whether the database of forests with high conservation value (key-biotopes) could be used in machine learning to train a model to recognise similar forests. In particular, one need to answer the following:\n",
    "\n",
    "    - Is this dataset appropriate to use as training data?\n",
    "    - If yes, how should the data set be prepared to be optimal training data? For example:\n",
    "        - Should the dataset be divided into subsets of sites that exhibit similar characteristics? Which characteristics?\n",
    "        - Should the polygons be edited in some way to improve accuracy?\n",
    "    - Is more data needed?\n",
    "\n",
    "## Our Proposal\n",
    "We choose to divide key-biotopes by the types of habitats they contain. Then run a simple learning algorithm on Laser data (stored in `.laz` files) and see whether we can distinguish areas with that include particular Key-Biotopes from others.\n",
    "\n",
    "### Method:\n",
    "Laser measurements are available for square areas, 2.5 km X 2.5 km. To facilitate analysis, we will do it in steps:\n",
    "\n",
    "- **Step 1:** Divide these squares into smaller squares of equal areas (called henceforth tiles)\n",
    "- **Step 2:** Compute the percentage of area within a tile which is occupied by key-biotopes. Then, according to these percentages, label tiles for whether they contain key-bishops or not, i.e. a positive set and a negative set.\n",
    "- **Step 3:** From the laser data, compute a set of variables that characterize each tile.\n",
    "- **Step 4:** Apply a classification algorithm on the resulting dataset.\n",
    "\n",
    "### Choices:\n",
    "In the following we will only attempt a simplified application of the solution. There are several parameters which will affect the subsequent learning, and -in principle- they should be fine tuned systematically or through trial and error. Instead, we will just make some naive choices.\n",
    "\n",
    "1. We choose to analyse tiles that include coniferous forests (Barrskogar) as key-biotopes. You are welcome to pick a different habitat type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad00743",
   "metadata": {},
   "outputs": [],
   "source": [
    "HABITAT = 'Barrskogar'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1744c4",
   "metadata": {},
   "source": [
    "2. Selecting the size of tiles.\n",
    "    - If the size is small (high resolution): one gets a bigger number of tiles to compare. There is a higher probability to get tiles that are fully covered by key-biotopes and hence their characteristics will correspond perfectly to key-biotopes. However, if the size is too small a tile might fail to capture the characteristics that define the key-biotope.\n",
    "    - If the size is big (low resolution): a tile with a bigger size might capture better the overall properties that define a key-biotope from everything else. Also a smaller dataset will be less expensive to analyse. However, if the size is too big we will lose all ability to differentiate key-biotopes.\n",
    "    \n",
    "We should try different sizes to systematically arrive to the optimum value. But, for simplicity, we will just select a to **divide each laser square into 10 X 10 smaller squares, i.e. tiles of size 250m X 250m.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1fee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "TILE_SIZE = 250*250 # in meters\n",
    "DIV_SIDE = 10 # divide each side of a laser square by this value\n",
    "DIV_AREA = 100 # divide the area into 100 squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9e6573",
   "metadata": {},
   "source": [
    "3. We choose to label a tile as containing a key-beat-up if 50% or more of its area is covered by key-biotopes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fc0308",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856c162f",
   "metadata": {},
   "source": [
    "# Step 1:\n",
    "In this step we will be concerned with laser data referenced in 'rutor_shapefiles'. Remember 'rutor_shapefiles' describe square-shaped areas in Sweden for which laser measurements are available (and stored in `.laz` files). We aim to divide each square area into 100 equal square tiles.\n",
    "\n",
    "## 1.1 Load The Data, Explore and Filter\n",
    "- To Do:\n",
    "1. Import the necessary modules.\n",
    "2. Load 'rutor_shapefiles' into a GeoDataFrame.\n",
    "3. Explore the data, drop all uninformative columns. Note: in the following analysis, we also won't be needing any dates.\n",
    "4. Read Coordinate Reference System (CRS) of the GeoDataFrame. What are the units of distance in this CRS?\n",
    "5. Currently we only have access to laser data of the year 2020, i.e. folders (column 'Block') starting with the number '20' as in `20A012` to `20F050`. Filter your GeoDataFrame accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a2f204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7138401",
   "metadata": {},
   "source": [
    "## 1.2 Split\n",
    "- To Do:\n",
    "1. Write a function that produces a rectangular polygon from four values (x_min, y_min, x_max, y_max). (x_min, y_min) is lower left corner, and (x_max, y_max) is the upper right corner.\n",
    "        - Import the needed module from `shapely`.\n",
    "2. Similar to 1, write a function that returns a list of $nXn$ rectangles instead of one. $n$ is some integer.\n",
    "3. Write a function that produces a list of $nXn$ squares from a square polygon.\n",
    "        - `polygon.bounds` gives the values (x_min, y_min, x_max, y_max)\n",
    "4. Now utilize the function from the last point. Write a new empty GeoDataFrame. Fill its 'geometry' by dividing the polygons from the geometry of GeoDataFrame from the previous section. Add CRS information to the new GeoDataFrame.\n",
    "5. Fill the data of the new GeoDataFrame with the corresponding values from columns: 'square', 'Block', 'Las_Namn'. Add a new code to identify each tile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c529e4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bb9a89f",
   "metadata": {},
   "source": [
    "# Step 2:\n",
    "Now that we have divided the area into tiles, it's time to determine how much of their area is occupied by coniferous forests key-biotopes. Remember 'keybiotopes_habitatgroups_shapefiles':\n",
    "- These shapefiles are the result of the first set of exercises analysing sksNyckelBiotoper_shapefiles. Both shapefiles display the locations and attributes of the key biotopes (Nyckelbiotoper) in Sweden.\n",
    "\n",
    "In this step we will find the subset of key-biotopes that contain coniferous forests (a subset of 'keybiotopes_habitatgroups_shapefiles'), then find the intersection between this subset and the tiles from step 1.\n",
    "\n",
    "## 2.1 Load and Filter Data\n",
    "- To Do:\n",
    "1. Read 'keybiotopes_habitatgroups_shapefiles' into a GeoDataFrame.\n",
    "2. Find the subset of keybiotopes which include coniferous forests (Barrskogar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a5ded6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "569eb077",
   "metadata": {},
   "source": [
    "## 2.2 Intersection and Key-biotope Ratio\n",
    "- To Do:\n",
    "1. Find the intersection between the subset of key-biotopes and laser tiles.\n",
    "2. The area of each tile is TILE_SIZE, find the ratio occupied by key-biotopes for each tile\n",
    "        -  use function `groupby`\n",
    "3. Get a column with these ratios and add it to the GeoDataFrame of all tiles. Note tiles not in the intersection will have ratio = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfb802b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1aef4cda",
   "metadata": {},
   "source": [
    "## 2.3 Which Tiles Contain Key-biotopes?\n",
    "- To Do:\n",
    "1. Add a new column to the tiles' GeoDataFrame that labels a tile as 'contains key-biotopes' (value = 1) or 'doesn't contain key-biotopes (value = 0). This should depend on whether area occupied by key-biotopes in a tile exceed the threshold 50% of the total area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc219470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51713649",
   "metadata": {},
   "source": [
    "## 2.4 Write The Result\n",
    "- To Do:\n",
    "1. Write the tiles' GeoDataFrame into a shapefile to use in the next steps of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bc1032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "geo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
